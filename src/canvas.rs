use std::iter::once;
use anyhow::Error;
use wgpu::{
    Backends, CommandEncoderDescriptor, CompositeAlphaMode, Device, DeviceDescriptor, Features,
    Limits, PresentMode, Queue, RequestAdapterOptions, Surface,
    SurfaceConfiguration, SurfaceError, TextureFormat, TextureUsages, TextureViewDescriptor, InstanceDescriptor,
};
use winit::window::Window;

use crate::{camera::Camera, canvas_render_pipeline::CanvasRenderPipeline};

pub struct Canvas {
    /// Width of output surface in pixels.
    width: u32,
    /// Height of output surface in pixels.
    height: u32,
    /// The surface we are rendering to. It is linked to the inner part of the window passed in the
    /// constructor.
    surface: Surface,
    /// The format of the texture. It is acquired using the preferred format of the adapter and we
    /// remember it, so we can recreate the surface if it becomes invalid.
    format: TextureFormat,
    /// A device is used to create buffers (for exchanging data with the GPU) among other things.
    device: Device,
    /// Used to send command generated by the render pipline to the GPU and write to buffers.
    queue: Queue,
    render_pipeline: CanvasRenderPipeline,
}

impl Canvas {
    /// Construct a new canvas and link it to a window. Height and width are specified in pixels.
    pub async unsafe fn new(
        width: u32,
        height: u32,
        window: &Window,
    ) -> Result<Self, Error> {
        let instance = wgpu::Instance::new(InstanceDescriptor { backends: Backends::PRIMARY, dx12_shader_compiler: wgpu::Dx12Compiler::Fxc});
        let surface = unsafe { instance.create_surface(&window)? };
        let adapter = instance
            .request_adapter(&RequestAdapterOptions {
                power_preference: wgpu::PowerPreference::HighPerformance,
                force_fallback_adapter: false,
                compatible_surface: Some(&surface),
            })
            .await
            .unwrap();
        // Can be used for API call tracing if that feature is enabled.
        let trace_path = None;
        let (device, queue) = adapter
            .request_device(
                &DeviceDescriptor {
                    label: None,
                    features: Features::empty(),
                    limits: Limits::default(),
                },
                trace_path,
            )
            .await?;
        let caps = surface.get_capabilities(&adapter);
        // The first format in the array is the prefered one.
        let format = caps.formats[0];

        let render_pipeline = CanvasRenderPipeline::new(&device, format);

        let canvas = Self {
            width,
            height,
            surface,
            device,
            queue,
            format,
            render_pipeline,
        };
        canvas.configure_surface();

        Ok(canvas)
    }

    /// Resize canvas to new size in pixels. Ignored if either width or height is zero.
    pub fn resize(&mut self, width: u32, height: u32) {
        // May be resized to an empty surface in case window is minimized. This would crash the
        // application, so we ignore resizing to an empty texture.
        if width != 0 || height != 0 {
            self.width = width;
            self.height = height;
            self.configure_surface();
        }
    }

    pub fn render(&self, camera: &Camera) -> Result<(), SurfaceError> {
        let output = match self.surface.get_current_texture() {
            Ok(output) => output,
            // Surface Lost => Reconfigure surface
            Err(SurfaceError::Lost) => {
                self.configure_surface();
                self.surface.get_current_texture()?
            }
            Err(other) => return Err(other),
        };
        let view = output
            .texture
            .create_view(&TextureViewDescriptor::default());
        let mut encoder = self
            .device
            .create_command_encoder(&CommandEncoderDescriptor {
                label: Some("Render Encoder"),
            });
        self.render_pipeline
            .update_buffers(&self.queue, camera.inv_view());
        self.render_pipeline.draw_to(&view, &mut encoder);
        self.queue.submit(once(encoder.finish()));
        output.present();
        Ok(())
    }

    fn configure_surface(&self) {
        let config = SurfaceConfiguration {
            usage: TextureUsages::RENDER_ATTACHMENT,
            format: self.format,
            width: self.width,
            height: self.height,
            present_mode: PresentMode::AutoVsync,
            alpha_mode: CompositeAlphaMode::Opaque,
            view_formats: vec![],
        };
        self.surface.configure(&self.device, &config)
    }
}
